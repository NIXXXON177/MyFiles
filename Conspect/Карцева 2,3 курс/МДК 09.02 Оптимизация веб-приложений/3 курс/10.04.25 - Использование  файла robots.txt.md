•Robots.txt — это текстовый файл, который содержит параметры индексирования сайта для роботов поисковых систем.

•Яндекс поддерживает [стандарт](http://www.robotstxt.org/robotstxt.html) [](http://www.robotstxt.org/robotstxt.html)[исключений](http://www.robotstxt.org/robotstxt.html) [](http://www.robotstxt.org/robotstxt.html)[для](http://www.robotstxt.org/robotstxt.html) [](http://www.robotstxt.org/robotstxt.html)[роботов](http://www.robotstxt.org/robotstxt.html) (Robots Exclusion Protocol) с расширенными возможностями.

При очередном обходе сайта робот Яндекса загружает файл robots.txt. Если при последнем обращении к файлу, страница или раздел сайта запрещены, робот не проиндексирует их.

# Требования к файлу robots.txt

Роботы Яндекса корректно обрабатывают robots.txt, если:
	- Размер файла не превышает 500 КБ.
	- Это TXT-файл с названием robots — robots.txt.
	- Файл размещен в корневом каталоге сайта.
	- Файл доступен для роботов — сервер, на котором размещен сайт, отвечает HTTP-кодом со статусом 200 OK. [Проверьте](https://webmaster.yandex.ru/tools/server-response/) [](https://webmaster.yandex.ru/tools/server-response/)[ответ](https://webmaster.yandex.ru/tools/server-response/) [](https://webmaster.yandex.ru/tools/server-response/)[сервера](https://webmaster.yandex.ru/tools/server-response/)
	- Если файл не соответствует требованиям, сайт считается открытым для индексирования.

Яндекс поддерживает редирект с файла robots.txt, расположенного на одном сайте, на файл, который расположен на другом сайте. В этом случае учитываются директивы в файле, на который происходит перенаправление. Такой редирект может быть удобен при [переезде](https://yandex.ru/support/webmaster/yandex-indexing/moving-site.html) [](https://yandex.ru/support/webmaster/yandex-indexing/moving-site.html)[сайта](https://yandex.ru/support/webmaster/yandex-indexing/moving-site.html).